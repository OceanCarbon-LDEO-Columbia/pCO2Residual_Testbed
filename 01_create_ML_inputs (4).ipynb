{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2c2d954-9107-43ce-a32d-4c342dde6e17",
   "metadata": {},
   "source": [
    "<span style=\"color:hotpink; font-size:40px; font-weight:bold;\">Packages and imports</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c0f50fa-8734-4017-bf34-d45d2eecfb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 21:13:10.165009: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-22 21:13:10.176353: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-22 21:13:10.190782: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-22 21:13:10.194988: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-22 21:13:10.205098: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "### standard imports ###\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import gcsfs\n",
    "\n",
    "### Python file with supporting functions ###\n",
    "\n",
    "import residual_utils as prerun\n",
    "\n",
    "### set up for getting files from leap bucket ###\n",
    "\n",
    "fs = gcsfs.GCSFileSystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b85b39-edd8-4308-80ab-d932e0c00cc0",
   "metadata": {},
   "source": [
    "<span style=\"color:hotpink; font-size:40px; font-weight:bold;\">Setting date range</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51e85a9b-091c-49b0-a2c5-37c4a8f9dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting the date range to unify the date type ###\n",
    "\n",
    "# Define date range\n",
    "date_range_start = '1982-02-01T00:00:00.000000000'\n",
    "date_range_end = '2023-12-31T00:00:00.000000000'\n",
    "\n",
    "# create date vector, adds 14 days to start & end\n",
    "dates = pd.date_range(start=date_range_start, \n",
    "                      end=date_range_end,freq='MS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48f34c7-f95c-4f5f-8b17-ab2942757657",
   "metadata": {},
   "source": [
    "<span style=\"color:hotpink; font-size:40px; font-weight:bold;\">Setting paths</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7b0da0-1512-4e7b-b254-bfac2ec55622",
   "metadata": {},
   "outputs": [],
   "source": [
    "### set paths ###\n",
    "\n",
    "### paths for loading: ###\n",
    "\n",
    "# directory of regridded members from notebook 00\n",
    "ensemble_dir = \"gs://leap-persistent/abbysh/pco2_residual_1982-2023/00_regridded_members\" # path to regridded data\n",
    "\n",
    "# directory of reference zarr files\n",
    "zarr_dir = 'gs://leap-persistent/abbysh/zarr_files_'\n",
    "\n",
    "# atmospheric xco2 file\n",
    "xco2_path = f\"{zarr_dir}/xco2_cmip6_183501-224912_monthstart.zarr\"\n",
    "\n",
    "# socat data file\n",
    "socat_path = f\"{zarr_dir}/socat_mask_feb1982-dec2023.zarr\"\n",
    "\n",
    "# topo and land-sea masks\n",
    "topo_path = f\"{zarr_dir}/GEBCO_2014_1x1_global.zarr\"\n",
    "lsmask_path = f\"{zarr_dir}/lsmask.zarr\"\n",
    "\n",
    "#############################################\n",
    "\n",
    "### paths for saving: ###\n",
    "\n",
    "your_username = \n",
    "\n",
    "# directory of where to save ML inputs from this (01) notebook (save it in your bucket!!)\n",
    "xgb_data_dir = f\"gs://leap-persistent/{your_username}/pco2_residual/post01_xgb_inputs\" # where to store cleaned data from 01 (this notebook), for use in 02 notebook, for xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca1bf0f-a66c-4cf0-adfc-2b10c6b544ef",
   "metadata": {},
   "source": [
    "<span style=\"color:hotpink; font-size:40px; font-weight:bold;\">Calculating chlorophyll climatology</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac783a3-0b38-44ca-8934-88dd975dccb7",
   "metadata": {},
   "source": [
    "Here is where clorophyll climatology is calculated. Climatology is calculated from model output 01-1998 through the end of the time period (here, 12-2023), by calculating the monthly average chlorophyll of the whole time period. This climatology is saved in a separate file in the individual regridded member folders. This file is currently used to set feature variables for ML in notebook 02, but those feature variables are not *actually used* for the ML. \n",
    "\n",
    "You do not need to run this code, because chlorophyll climatology is already saved in the regridded members directory that you're loading from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25079b36-0329-4c6e-b8b9-088699c42141",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### chl_clim code here ###\n",
    "\n",
    "# a = fs.ls(ensemble_dir)\n",
    "# for ens_path in a[1:]:\n",
    "#     ens = ens_path.split('/')[-1]\n",
    "#     mems = fs.ls(ens_path)\n",
    "#     for mem in mems:\n",
    "#         memo = mem.split('/')[-1]\n",
    "#         zarrs = fs.ls(mem)\n",
    "#         for z in zarrs:\n",
    "#             zarr_name = z.split('/')[-1]\n",
    "#             d = xr.open_mfdataset('gs://'+z,engine='zarr')\n",
    "#             chl = d.chl\n",
    "\n",
    "#             ### year selection ### remove hard code ###\n",
    "#             chl_clim = chl.sel(time=slice('1998-01-01', '2023-12-30')).groupby(\"time.month\").mean(\"time\")\n",
    "\n",
    "#             if 'lev_partial' in chl_clim.dims:\n",
    "#                 chl_clim = chl_clim.sel({'lev_partial':1},drop=True)\n",
    "            \n",
    "#             chl_out_new = xr.Dataset({'chl_clim':([\"month\",\"lat\",\"lon\"],chl_clim.data)},\n",
    "#                     coords={'time': (['month'],chl_clim.month.data),\n",
    "#                             'lon':(['lon'],chl_clim.xlon.data),\n",
    "#                             'lat': (['lat'],chl_clim.ylat.data)})\n",
    "            \n",
    "#             # print(chl_out_new)\n",
    "#             out_path = f'{ensemble_dir}/{ens}/{memo}/chlclim_{zarr_name}'\n",
    "#             print(out_path,chl_out_new)\n",
    "#             chl_out_new.to_zarr(out_path)\n",
    "#             print(f'finished with {ens}:{memo}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa8172a-c36a-4c38-aaea-fcc082406f6c",
   "metadata": {},
   "source": [
    "<span style=\"color:hotpink; font-size:40px; font-weight:bold;\">Loading list of ESMs and members in testbed</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327a0975-a6ab-466e-baf8-49fc0079ecab",
   "metadata": {},
   "source": [
    "<span style=\"color:lightblue; font-size:30px; font-weight:bold;\">For all members for each ESM</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2aed97-baa6-486a-be0f-017f0abea3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "### loads list of Earth System Models (\"ensembles\") and members for the full testbed ###\n",
    "\n",
    "ensembles = []\n",
    "for path in fs.ls(ensemble_dir):\n",
    "    ens = path.split('/')[-1].split('.')[0]\n",
    "    if ens not in ensembles:\n",
    "        ensembles.append(ens)\n",
    "\n",
    "mems_dict = dict()\n",
    "a = fs.ls(ensemble_dir)\n",
    "for ens_path in a:\n",
    "    ens = ens_path.split('/')[-1]\n",
    "    mems = fs.ls(ens_path)\n",
    "    for mem in mems:\n",
    "        memo = mem.split('/')[-1]\n",
    "        \n",
    "        if ens not in mems_dict:\n",
    "            mems_dict[ens] = [memo]\n",
    "\n",
    "        elif ens in mems_dict:\n",
    "            mems_dict[ens].append(memo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eed1ea-45b6-478c-938d-460c30e1084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mems_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff0ed15-1e6c-4d03-bae5-08d2c0251460",
   "metadata": {},
   "source": [
    "<span style=\"color:hotpink; font-size:40px; font-weight:bold;\">Running code to make ML inputs</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2decae71-ec96-413c-9c03-787be4647631",
   "metadata": {},
   "outputs": [],
   "source": [
    "### creating pandas dataframes out of \"raw\" data to prep for ML ###\n",
    "\n",
    "N_time = len(dates)\n",
    "member_counter = 0 \n",
    "\n",
    "### loop through each ESM\n",
    "for ens, mem_list in mems_dict.items(): \n",
    "\n",
    "    ### loop through each member of that ESM\n",
    "    for member in mem_list:\n",
    "        \n",
    "        print(f'making dataframe {member_counter}: {ens,member}')\n",
    "\n",
    "        ### uses utility function file to make data into dataframe for ML use\n",
    "        df = prerun.create_inputs(ensemble_dir, ens, member, dates, N_time,\n",
    "                                  xco2_path,\n",
    "                                  socat_path,\n",
    "                                  topo_path,\n",
    "                                  lsmask_path)\n",
    "\n",
    "        ### Save the pandas dataframe to workspace\n",
    "        prerun.save_clean_data(df, xgb_data_dir, ens, member, dates)\n",
    "        member_counter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
